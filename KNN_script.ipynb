{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**CS 4774: Machine Learning Final Project - KMeans Approach**\n",
    "\n",
    "Author: Donovan Ray (DonovanRay26)"
   ],
   "id": "7c655c3dec96ff15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We'll utilize pandas, numpy, and sklearn to preprocess our data, imputing numerical features and applying one-hot encoding to categorical features. "
   ],
   "id": "eac6146679462d5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:39:30.569452Z",
     "start_time": "2025-04-21T03:39:30.164931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# training data:\n",
    "train_raw = pd.read_csv('data/train.csv')\n",
    "test_raw = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(\"Train data shape: \", train_raw.shape)\n",
    "print(\"Test data shape: \", test_raw.shape)\n",
    "print(train_raw.head())\n",
    "\n",
    "# get features and targets:\n",
    "X_train = train_raw.drop(['SalePrice', 'Id'], axis=1)  # I think that only Id needs to be dropped before PCA\n",
    "y_train = train_raw[\"SalePrice\"]\n",
    "X_test = test_raw.copy()  # can just copy as test.csv doesn't have the target\n",
    "\n",
    "# separate numerical and categorical features:\n",
    "numFeatures = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "catFeatures = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# utilize pipelines for preprocessing:\n",
    "\n",
    "numPipeline = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                        ('scaler', StandardScaler())])\n",
    "\n",
    "catPipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "# combine workflows:\n",
    "preprocessor = ColumnTransformer([('numerical', numPipeline, numFeatures),\n",
    "                                  ('categorical', catPipeline, catFeatures)])\n",
    "\n",
    "# now, fit and transform data:\n",
    "\n",
    "# use preprocessor to process train and test data:\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# convert to pd dataframes:\n",
    "\n",
    "# need to concatenate processed numerical and categorical features:\n",
    "numFeature_names = numFeatures\n",
    "catFeature_names = preprocessor.named_transformers_['categorical'].named_steps['onehot'].get_feature_names_out(catFeatures)\n",
    "\n",
    "# concatenate\n",
    "totalFeatures = np.concatenate((numFeature_names, catFeature_names))\n",
    "\n",
    "# convert to dataframes:\n",
    "X_train_processed = pd.DataFrame(X_train_processed, columns=totalFeatures)\n",
    "X_test_processed = pd.DataFrame(X_test_processed, columns=totalFeatures)\n",
    "\n",
    "print(\"Processed Train dataset: \", X_train_processed.shape)\n",
    "print(\"Processed Test dataset: \", X_test_processed.shape)\n",
    "print(X_train_processed.head())\n",
    "\n",
    "# write out preprocessed data:\n",
    "X_train_processed.to_csv('data/train_processed.csv', index=False)\n",
    "X_test_processed.to_csv('data/test_processed.csv', index=False)"
   ],
   "id": "30e746f4b4debe6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (1460, 81)\n",
      "Test data shape:  (1459, 80)\n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "Processed Train dataset:  (1460, 288)\n",
      "Processed Test dataset:  (1459, 288)\n",
      "         Id  MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  \\\n",
      "0 -1.730865    0.073375    -0.220875 -0.207142     0.651479    -0.517200   \n",
      "1 -1.728492   -0.872563     0.460320 -0.091886    -0.071836     2.179628   \n",
      "2 -1.726120    0.073375    -0.084636  0.073480     0.651479    -0.517200   \n",
      "3 -1.723747    0.309859    -0.447940 -0.096897     0.651479    -0.517200   \n",
      "4 -1.721374    0.073375     0.641972  0.375148     1.374795    -0.517200   \n",
      "\n",
      "   YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  \\\n",
      "0   1.050994      0.878668    0.514104    0.575425  ...             0.0   \n",
      "1   0.156734     -0.429577   -0.570750    1.171992  ...             0.0   \n",
      "2   0.984752      0.830215    0.325915    0.092907  ...             0.0   \n",
      "3  -1.863632     -0.720298   -0.570750   -0.499274  ...             0.0   \n",
      "4   0.951632      0.733308    1.366489    0.463568  ...             0.0   \n",
      "\n",
      "   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
      "0           0.0           0.0          1.0                    0.0   \n",
      "1           0.0           0.0          1.0                    0.0   \n",
      "2           0.0           0.0          1.0                    0.0   \n",
      "3           0.0           0.0          1.0                    1.0   \n",
      "4           0.0           0.0          1.0                    0.0   \n",
      "\n",
      "   SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
      "0                    0.0                   0.0                   0.0   \n",
      "1                    0.0                   0.0                   0.0   \n",
      "2                    0.0                   0.0                   0.0   \n",
      "3                    0.0                   0.0                   0.0   \n",
      "4                    0.0                   0.0                   0.0   \n",
      "\n",
      "   SaleCondition_Normal  SaleCondition_Partial  \n",
      "0                   1.0                    0.0  \n",
      "1                   1.0                    0.0  \n",
      "2                   1.0                    0.0  \n",
      "3                   0.0                    0.0  \n",
      "4                   1.0                    0.0  \n",
      "\n",
      "[5 rows x 288 columns]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Implementation of K Nearest Neighbors\n",
    "\n",
    "Will use Euclidian and Manhattan distance, as well as weighted and unweighted KNN"
   ],
   "id": "3ad107733ff10b81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T15:01:47.381467Z",
     "start_time": "2025-04-21T15:01:47.373467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k, distance, weighted=False):\n",
    "        self.k = k\n",
    "        self.distance = distance\n",
    "        self.weighted = weighted\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.pca = None\n",
    "        \n",
    "    # fit\n",
    "    def fit(self, X, y, pca_components=None):\n",
    "        # fit with PCA (if chosen):\n",
    "        if pca_components is not None:\n",
    "            self.pca = PCA(n_components=pca_components)\n",
    "            self.X_train = self.pca.fit_transform(X)\n",
    "            \n",
    "        # normal fit:\n",
    "        else:\n",
    "            self.X_train = X if isinstance(X, list) else X\n",
    "        self.y_train = y if isinstance(y, list) else y\n",
    "        \n",
    "        # convert to numpy arrays:\n",
    "        self.X_train = np.array(self.X_train)\n",
    "        self.y_train = np.array(self.y_train)\n",
    "        \n",
    "    # helper method to calculate distances:\n",
    "    def calculateDistance(self, p1, p2):\n",
    "        p1 = np.array(p1, dtype=float)\n",
    "        p2 = np.array(p2, dtype=float)\n",
    "        if self.distance.lower() == 'manhattan':\n",
    "            return np.sum(np.abs(p1 - p2))\n",
    "        elif self.distance.lower() == 'euclidian':\n",
    "            return np.sqrt(np.sum(p1 - p2) ** 2) \n",
    "        elif self.distance.lower() == 'chebyshev':\n",
    "            return np.max(np.abs(p1 - p2))\n",
    "        elif self.distance.lower() == 'cosine similarity':\n",
    "            norm_p1 = np.linalg.norm(p1)\n",
    "            norm_p2 = np.linalg.norm(p2)\n",
    "            \n",
    "            if norm_p1 == 0 or norm_p2 == 0:\n",
    "                return 1.0\n",
    "            else:\n",
    "                cosSim = np.dot(p1, p2) / (norm_p1 * norm_p2)\n",
    "                return 1 - cosSim\n",
    "        \n",
    "        else:\n",
    "            return None  # invalid metric\n",
    "         \n",
    "    # predict\n",
    "    def predict(self, X):\n",
    "        if self.pca:\n",
    "            X = self.pca.transform(X)\n",
    "        else:\n",
    "            X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "            \n",
    "        predictions = []\n",
    "        \n",
    "        for x in X:\n",
    "            # compute distance:\n",
    "            distances = [self.calculateDistance(x, x_train) for x_train in self.X_train]\n",
    "            \n",
    "            # get knns\n",
    "            knn_indices = np.argsort(distances)[:self.k]\n",
    "            knn_distances = [distances[i] for i in knn_indices]\n",
    "            knn_prices = [self.y_train[i] for i in knn_indices]\n",
    "            \n",
    "            # if weighted:\n",
    "            if self.weighted:\n",
    "                weights = 1 / np.array(knn_distances) + 1e-8  # avoid div by 0\n",
    "                prediction = np.average(knn_prices, weights=weights)\n",
    "            else:\n",
    "                # calculate prediction using mean price of knns:\n",
    "                prediction = np.mean(knn_prices)\n",
    "            \n",
    "            # append prediction:\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    # get accuracy metrics in format [RMSE, MAE, R2]:\n",
    "    def measure_accuracy(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        RMSE = np.sqrt(mean_squared_error(y, y_pred))\n",
    "        MAE = mean_absolute_error(y, y_pred)\n",
    "        R2 = r2_score(y, y_pred)\n",
    "        return [RMSE, MAE, R2]\n"
   ],
   "id": "38d96c597872e840",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Application of Model:\n",
    "\n",
    "Utilize an 80/20 test-train split on training data and calculate error to find best configuration for optimal KNN model."
   ],
   "id": "d9d9682921eb6f2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T15:43:25.489151Z",
     "start_time": "2025-04-21T15:43:09.099116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load data:\n",
    "X = pd.read_csv('data/train_processed.csv')\n",
    "y = pd.read_csv('data/train.csv')['SalePrice']\n",
    "competition_test = pd.read_csv('data/test_processed.csv')\n",
    "raw_competition_test = pd.read_csv('data/test.csv')  # don't use processed file for the Id's\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "bestRMSE_stats = [None, None, None, None]  # format: RMSE, k, pca, weighted?\n",
    "\n",
    "# find the best choice of k:\n",
    "\n",
    "\"\"\"\n",
    "for k in [2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    for pca in [2, 3, 5, 10, 15, 25, 30]:\n",
    "        for weighted in [True, False]:\n",
    "            knn = KNN(k=k, distance='cosine similarity', weighted=weighted)\n",
    "            knn.fit(X_train, y_train, pca_components=pca)\n",
    "            [RMSE, MAE, R2] = knn.measure_accuracy(X_test, y_test)\n",
    "            print(f'k = {k}, pca = {pca}, weighted: {weighted}  |  RMSE = {RMSE:.2f} | MAE = {MAE:.2f} | R2 = {R2:.2f}')\n",
    "            \n",
    "            if bestRMSE_stats[0] is None:\n",
    "                bestRMSE_stats = [RMSE, MAE, R2, k, pca, weighted]\n",
    "            elif bestRMSE_stats[0] > RMSE:\n",
    "                bestRMSE_stats = [RMSE, MAE, R2, k, pca, weighted]\n",
    "\n",
    "print(f'Best Configuration: k: {bestRMSE_stats[3]} | pca: {bestRMSE_stats[4]} | weighted: {bestRMSE_stats[5]} | RMSE: {bestRMSE_stats[0]:.2f} | MAE: {bestRMSE_stats[1]:.2f} | R2: {bestRMSE_stats[2]:.2f}')\n",
    "\"\"\"\n",
    "# make prediction of test data using optimal model:\n",
    "\n",
    "# optimal Manhattan configuration: k = 3 | 2 PCA components | weighted\n",
    "# optimal Chebyshev configuration: k = 4 | 5 PCA components | weighted\n",
    "\n",
    "knn_manhattan = KNN(k=3, distance='manhattan', weighted=True)\n",
    "knn_manhattan.fit(X_train, y_train, pca_components=2)\n",
    "knn_manhattan_pred = knn_manhattan.predict(competition_test)\n",
    "\n",
    "knn_chebyshev = KNN(k=4, distance='chebyshev', weighted=True)\n",
    "knn_chebyshev.fit(X_train, y_train, pca_components=5)\n",
    "knn_chebyshev_pred = knn_chebyshev.predict(competition_test)\n",
    "\n",
    "# write out predictions:\n",
    "manhattanDF = pd.DataFrame({'Id': raw_competition_test['Id'], \n",
    "                            'SalePrice': knn_manhattan_pred})\n",
    "chebyshevDF = pd.DataFrame({'Id': raw_competition_test['Id'],\n",
    "                            'SalePrice': knn_chebyshev_pred})\n",
    "manhattanDF.to_csv('data/manhattan_prediction.csv', index=False)\n",
    "chebyshevDF.to_csv('data/chebyshev_prediction.csv', index=False)\n",
    "print(\"Complete.\")"
   ],
   "id": "5a9a9dc00772579c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Current Results:\n",
    "\n",
    "Euclidian Distance: k = 9, 3 PCA components, not weighted, RMSE = 57148.57, MAE = 38546.71, R2: 0.58\n",
    "\n",
    "Manhattan Distance: k = 3, 2 PCA components, weighted, RMSE = 31922.75, MAE = 22905.35, R2: 0.87\n",
    "\n",
    "Chebyshev Distance: k = 4, 5 PCA components, weighted, RMSE = 31039.14, MAE = 19930.17, R2: 0.87\n",
    "\n",
    "Cosine Similarity: k = 10, 5 PCA components, weighted, RMSE = 36058.40, MAE = 21516.81, R2: 0.83\n",
    "\n",
    "It would seem that choice of distance metric plays a large role in the effectivity of the model. Euclidian distance yields the worst overall results, Cosine Similarity comes in second with fairly strong results, and Manhattan and Chebyshev are tied for first in terms of R2 score, but Chebyshev has a slightly lower RMSE and MAE.\n",
    "\n",
    "I will submit both a Chebyshev and Manhattan model to the competition with the specified configurations and compare results.\n",
    "\n",
    "The Chebyshev distance KNN model received a score of 19423.31579, and the Manhattan distance KNN model received a score of 22953.36611. Thus, the KNN model that leveraged the Chebyshev distance metric performed better, and ranked 3500/6880 in the Kaggle competition. "
   ],
   "id": "58c4b5fdbdfeb04"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
